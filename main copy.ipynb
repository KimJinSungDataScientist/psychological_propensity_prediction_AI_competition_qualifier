{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from string import ascii_lowercase\n",
    "from itertools import combinations\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train = pd.read_csv('./data/train.csv').drop('index',axis=1)\n",
    "# train.drop('introelapse',axis=1,inplace=True)\n",
    "# family size 이상치\n",
    "train = train.drop(1019)\n",
    "# age 이상치\n",
    "train = train.drop(train[train['age']>100].index.to_list())\n",
    "train = train.drop(train[train['familysize']>100].index.to_list())\n",
    "# train = train.drop(train[train['introelapse']>3000].index.to_list())\n",
    "# train = train.drop(train[train['testelapse']>10000].index.to_list())\n",
    "# train = train.drop(train[train['surveyelapse']>10000].index.to_list()) # 나에 대한 추가 질문\n",
    "\n",
    "test = pd.read_csv('./data/test.csv').drop('index',axis=1)\n",
    "# test.drop('introelapse',axis=1,inplace=True)\n",
    "test.loc[test['familysize']>100,'familysize']= train['familysize'].mean()\n",
    "test.loc[test['age']>100,'age']= train['age'].mean()\n",
    "# test.loc[test['introelapse']>3000,'introelapse']= train['introelapse'].mean()\n",
    "# test.loc[test['testelapse']>10000,'testelapse']= train['testelapse'].mean()\n",
    "# test.loc[test['surveyelapse']>10000,'surveyelapse']= train['surveyelapse'].mean()\n",
    "\n",
    "test_index = pd.read_csv('./data/test.csv')['index']\n",
    "\n",
    "pd.set_option('display.max_row', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "value = train['country'].value_counts().values\n",
    "rank = list(map(lambda x : 1 if x>1000 else (2 if x>100 else 3),value))\n",
    "# rank = list(map(lambda x : 1 if x>1000 else (2 if x>500 else (3 if x>200 else (4 if x>100 else 5))),value))\n",
    "temp_dict = {i : 0 for i in train['country'].value_counts().index.to_list()}\n",
    "\n",
    "rank_dict = dict(zip(train['country'].value_counts().index.to_list(), rank))\n",
    "rank_dict['nan'] = 0\n",
    "train['country'] = train['country'].fillna('nan')\n",
    "train['country'] = train['country'].apply(lambda x : rank_dict[x])\n",
    "\n",
    "\n",
    "train['Ex'] = (train['TIPI1']+train['TIPI6'])/2\n",
    "train['Ag'] = (train['TIPI7']+train['TIPI2'])/2\n",
    "train['Con'] = (train['TIPI3']+train['TIPI8'])/2\n",
    "train['Es'] =(train['TIPI9']+train['TIPI4'])/2\n",
    "train['Op'] =(train['TIPI5']+train['TIPI10'])/2\n",
    "\n",
    "train['mach_score'] = train[train.columns[:20]].apply(lambda x : x.mean(),axis=1)\n",
    "train['T'] = train['Q1'] + train['Q2'] - train['Q3'] - train['Q6'] - train['Q7'] - train['Q10'] + train['Q12'] + train['Q15'] - train['Q16']\n",
    "train['V'] = -train['Q4'] + train['Q5'] + train['Q8'] - train['Q11'] + train['Q13'] - train['Q14'] - train['Q17'] + train['Q18'] + train['Q20']\n",
    "train['M'] = -train['Q9'] + train['Q19']\n",
    "train['introelapse'] = np.log1p(train['introelapse'])\n",
    "train['testelapse'] = np.log1p(train['testelapse'])\n",
    "train['surveyelapse'] = np.log1p(train['surveyelapse'])\n",
    "train.drop('hand',axis=1,inplace=True)\n",
    "train.drop(['VCL7','VCL8','VCL11'],axis=1,inplace=True)\n",
    "\n",
    "# train.drop(['country'],axis=1,inplace=True)\n",
    "\n",
    "## 6,7,8,9,11,12 의미 없어 보임\n",
    "# 6,8,10 실존하지 않는 단어 -> 얘네는 의미있게 작용하지 않을까?\n",
    "# -> 7,8,11 제거\n",
    "\n",
    "# train.drop([('TIPI'+str(i)) for i in range(1,11)],axis=1,inplace=True)\n",
    "# train.drop([('Q'+str(i)) for i in range(1,20)],axis=1,inplace=True)\n",
    "\n",
    "# train['nature_score'] = train[[('Q'+str(i)) for i in range(20,27)]].apply(lambda x : x.mean(),axis=1)\n",
    "# train.drop([('Q'+str(i)) for i in range(20,27)],axis=1,inplace=True)\n",
    "# train.drop(['country','hand','introelapse','testelapse','surveyelapse'],axis=1,inplace=True)\n",
    "# train.drop(['introelapse','testelapse','surveyelapse'],axis=1,inplace=True)\n",
    "train_fill_na = train.fillna(train.mean())\n",
    "\n",
    "\n",
    "value = test['country'].value_counts().values\n",
    "# rank = list(map(lambda x : 1 if x>1000 else (2 if x>100 else 3),value))\n",
    "rank = list(map(lambda x : 1 if x>1000 else (2 if x>500 else (3 if x>200 else (4 if x>100 else 5))),value))\n",
    "\n",
    "temp_dict = {i : 0 for i in test['country'].value_counts().index.to_list()}\n",
    "\n",
    "rank_dict = dict(zip(test['country'].value_counts().index.to_list(), rank))\n",
    "rank_dict['nan'] = 0\n",
    "test['country'] = test['country'].fillna('nan')\n",
    "test['country'] = test['country'].apply(lambda x : rank_dict[x])\n",
    "\n",
    "test['Ex'] = (test['TIPI1']+test['TIPI6'])/2\n",
    "test['Ag'] = (test['TIPI7']+test['TIPI2'])/2\n",
    "test['Con'] = (test['TIPI3']+test['TIPI8'])/2\n",
    "test['Es'] =(test['TIPI9']+test['TIPI4'])/2\n",
    "test['Op'] =(test['TIPI5']+test['TIPI10'])/2\n",
    "\n",
    "test['mach_score'] = test[test.columns[:20]].apply(lambda x : x.mean(),axis=1)\n",
    "test['T'] = test['Q1'] + test['Q2'] - test['Q3'] - test['Q6'] - test['Q7'] - test['Q10'] + test['Q12'] + test['Q15'] - test['Q16']\n",
    "test['V'] = -test['Q4'] + test['Q5'] + test['Q8'] - test['Q11'] + test['Q13'] - test['Q14'] - test['Q17'] + test['Q18'] + test['Q20']\n",
    "test['M'] = -test['Q9'] + test['Q19']\n",
    "\n",
    "test['introelapse'] = np.log1p(test['introelapse'])\n",
    "test['testelapse'] = np.log1p(test['testelapse'])\n",
    "test['surveyelapse'] = np.log1p(test['surveyelapse'])\n",
    "test.drop('hand',axis=1,inplace=True)\n",
    "test.drop(['VCL7','VCL8','VCL11'],axis=1,inplace=True)\n",
    "# test.drop([('TIPI'+str(i)) for i in range(1,11)],axis=1,inplace=True)\n",
    "# test.drop([('Q'+str(i)) for i in range(1,20)],axis=1,inplace=True)\n",
    "\n",
    "test['nature_score'] = test[[('Q'+str(i)) for i in range(20,27)]].apply(lambda x : x.mean(),axis=1)\n",
    "# test.drop([('Q'+str(i)) for i in range(20,27)],axis=1,inplace=True)\n",
    "# test.drop(['country','hand','introelapse','testelapse','surveyelapse'],axis=1,inplace=True)\n",
    "test.drop(['country'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "test_fill_na = test.fillna(test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "\n",
    "clf = setup(data = train, target = 'nerdiness',remove_outliers=True,fix_imbalance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compare_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kimjinsung/Desktop/psychological_propensity_prediction_AI_competition_qualifier/main copy.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223131372e31362e34322e3232222c2275736572223a226b696d6a696e73756e67222c22706f7274223a323032347d/home/kimjinsung/Desktop/psychological_propensity_prediction_AI_competition_qualifier/main%20copy.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m best_3 \u001b[39m=\u001b[39m compare_models(sort \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAUC\u001b[39m\u001b[39m'\u001b[39m, n_select \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compare_models' is not defined"
     ]
    }
   ],
   "source": [
    "best_3 = compare_models(sort = 'AUC', n_select = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended = blend_models(estimator_list = best_3, fold = 5, method = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_holdout = predict_model(blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = finalize_model(blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_model(final_model, data = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = test_index\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"index\" : index,\n",
    "    \"nerdiness\" : predictions['Score']\n",
    "})\n",
    "submission.to_csv('./data/model_auto_ml.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_fill_na['nerdiness']\n",
    "x_train = train_fill_na.drop('nerdiness',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_fill_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits = 3, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "params = {'bagging_temperature': 0.375906, 'depth': 9.0, 'l2_leaf_reg': 68.8, 'learning_rate': 0.011, 'subsample': 0.76046}\n",
    "\n",
    "clf1 = CatBoostClassifier(**params, iterations=5000, eval_metric='AUC',allow_writing_files=False,od_type='Iter',random_state=777)\n",
    "clf2 = LGBMClassifier()\n",
    "clf3 = GradientBoostingClassifier()\n",
    "soft_vote  = VotingClassifier([('r1',clf1), ('r2', clf2), ('r3',clf3)], voting='soft')\n",
    "soft_vote.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = soft_vote\n",
    "pred_y = model.predict_proba(test_fill_na)\n",
    "pred_y = pred_y[:,1]\n",
    "\n",
    "index = test_index\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"index\" : index,\n",
    "    \"voted\" : pred_y\n",
    "})\n",
    "submission.to_csv('./data/model1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('./data/train.csv').drop('index',axis=1)\n",
    "# train.drop('introelapse',axis=1,inplace=True)\n",
    "# family size 이상치\n",
    "train = train.drop(1019)\n",
    "# age 이상치\n",
    "train = train.drop(train[train['age']>100].index.to_list())\n",
    "train = train.drop(train[train['familysize']>100].index.to_list())\n",
    "# train = train.drop(train[train['introelapse']>3000].index.to_list())\n",
    "# train = train.drop(train[train['testelapse']>10000].index.to_list())\n",
    "# train = train.drop(train[train['surveyelapse']>10000].index.to_list()) # 나에 대한 추가 질문\n",
    "\n",
    "test = pd.read_csv('./data/test.csv').drop('index',axis=1)\n",
    "# test.drop('introelapse',axis=1,inplace=True)\n",
    "test.loc[test['familysize']>100,'familysize']= train['familysize'].mean()\n",
    "test.loc[test['age']>100,'age']= train['age'].mean()\n",
    "# test.loc[test['introelapse']>3000,'introelapse']= train['introelapse'].mean()\n",
    "# test.loc[test['testelapse']>10000,'testelapse']= train['testelapse'].mean()\n",
    "# test.loc[test['surveyelapse']>10000,'surveyelapse']= train['surveyelapse'].mean()\n",
    "\n",
    "test_index = pd.read_csv('./data/test.csv')['index']\n",
    "\n",
    "pd.set_option('display.max_row', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "value = train['country'].value_counts().values\n",
    "rank = list(map(lambda x : 1 if x>1000 else (2 if x>100 else 3),value))\n",
    "# rank = list(map(lambda x : 1 if x>1000 else (2 if x>500 else (3 if x>200 else (4 if x>100 else 5))),value))\n",
    "\n",
    "temp_dict = {i : 0 for i in train['country'].value_counts().index.to_list()}\n",
    "\n",
    "rank_dict = dict(zip(train['country'].value_counts().index.to_list(), rank))\n",
    "rank_dict['nan'] = 0\n",
    "train['country'] = train['country'].fillna('nan')\n",
    "train['country'] = train['country'].apply(lambda x : rank_dict[x])\n",
    "train['Ex'] = (train['TIPI1']+train['TIPI6'])/2\n",
    "train['Ag'] = (train['TIPI7']+train['TIPI2'])/2\n",
    "train['Con'] = (train['TIPI3']+train['TIPI8'])/2\n",
    "train['Es'] =(train['TIPI9']+train['TIPI4'])/2\n",
    "train['Op'] =(train['TIPI5']+train['TIPI10'])/2\n",
    "\n",
    "train['mach_score'] = train[train.columns[:20]].apply(lambda x : x.mean(),axis=1)\n",
    "train['T'] = train['Q1'] + train['Q2'] - train['Q3'] - train['Q6'] - train['Q7'] - train['Q10'] + train['Q12'] + train['Q15'] - train['Q16']\n",
    "train['V'] = -train['Q4'] + train['Q5'] + train['Q8'] - train['Q11'] + train['Q13'] - train['Q14'] - train['Q17'] + train['Q18'] + train['Q20']\n",
    "train['M'] = -train['Q9'] + train['Q19']\n",
    "# train['introelapse'] = np.log1p(train['introelapse'])\n",
    "# train['testelapse'] = np.log1p(train['testelapse'])\n",
    "# train['surveyelapse'] = np.log1p(train['surveyelapse'])\n",
    "# train.drop('hand',axis=1,inplace=True)\n",
    "# train.drop(['VCL7','VCL8','VCL11'],axis=1,inplace=True)\n",
    "\n",
    "## 6,7,8,9,11,12 의미 없어 보임\n",
    "# 6,8,10 실존하지 않는 단어 -> 얘네는 의미있게 작용하지 않을까?\n",
    "# -> 7,8,11 제거\n",
    "\n",
    "# train.drop([('TIPI'+str(i)) for i in range(1,11)],axis=1,inplace=True)\n",
    "# train.drop([('Q'+str(i)) for i in range(1,20)],axis=1,inplace=True)\n",
    "\n",
    "train['nature_score'] = train[[('Q'+str(i)) for i in range(20,27)]].apply(lambda x : x.mean(),axis=1)\n",
    "# train.drop([('Q'+str(i)) for i in range(20,27)],axis=1,inplace=True)\n",
    "# train.drop(['country','hand','introelapse','testelapse','surveyelapse'],axis=1,inplace=True)\n",
    "train_fill_na = train.fillna(train.mean())\n",
    "\n",
    "\n",
    "value = test['country'].value_counts().values\n",
    "rank = list(map(lambda x : 1 if x>1000 else (2 if x>100 else 3),value))\n",
    "# rank = list(map(lambda x : 1 if x>1000 else (2 if x>500 else (3 if x>200 else (4 if x>100 else 5))),value))\n",
    "\n",
    "temp_dict = {i : 0 for i in test['country'].value_counts().index.to_list()}\n",
    "\n",
    "rank_dict = dict(zip(test['country'].value_counts().index.to_list(), rank))\n",
    "rank_dict['nan'] = 0\n",
    "test['country'] = test['country'].fillna('nan')\n",
    "test['country'] = test['country'].apply(lambda x : rank_dict[x])\n",
    "\n",
    "test['Ex'] = (test['TIPI1']+test['TIPI6'])/2\n",
    "test['Ag'] = (test['TIPI7']+test['TIPI2'])/2\n",
    "test['Con'] = (test['TIPI3']+test['TIPI8'])/2\n",
    "test['Es'] =(test['TIPI9']+test['TIPI4'])/2\n",
    "test['Op'] =(test['TIPI5']+test['TIPI10'])/2\n",
    "\n",
    "test['mach_score'] = test[test.columns[:20]].apply(lambda x : x.mean(),axis=1)\n",
    "test['T'] = test['Q1'] + test['Q2'] - test['Q3'] - test['Q6'] - test['Q7'] - test['Q10'] + test['Q12'] + test['Q15'] - test['Q16']\n",
    "test['V'] = -test['Q4'] + test['Q5'] + test['Q8'] - test['Q11'] + test['Q13'] - test['Q14'] - test['Q17'] + test['Q18'] + test['Q20']\n",
    "test['M'] = -test['Q9'] + test['Q19']\n",
    "\n",
    "# test['introelapse'] = np.log1p(test['introelapse'])\n",
    "# test['testelapse'] = np.log1p(test['testelapse'])\n",
    "# test['surveyelapse'] = np.log1p(test['surveyelapse'])\n",
    "# test.drop('hand',axis=1,inplace=True)\n",
    "# test.drop(['VCL7','VCL8','VCL11'],axis=1,inplace=True)\n",
    "# test.drop([('TIPI'+str(i)) for i in range(1,11)],axis=1,inplace=True)\n",
    "# test.drop([('Q'+str(i)) for i in range(1,20)],axis=1,inplace=True)\n",
    "\n",
    "test['nature_score'] = test[[('Q'+str(i)) for i in range(20,27)]].apply(lambda x : x.mean(),axis=1)\n",
    "# test.drop(['country','hand','introelapse','testelapse','surveyelapse'],axis=1,inplace=True)\n",
    "# test.drop([('Q'+str(i)) for i in range(20,27)],axis=1,inplace=True)\n",
    "test_fill_na = test.fillna(test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ls = train_fill_na.columns.to_list()\n",
    "temp_ls.remove('mach_score')\n",
    "temp_ls.remove('nature_score')\n",
    "temp_ls.remove('nerdiness')\n",
    "temp_ls.remove('country')\n",
    "temp_ls.remove('introelapse')\n",
    "temp_ls.remove('testelapse')\n",
    "temp_ls.remove('surveyelapse')\n",
    "temp_ls.remove('hand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in temp_ls:\n",
    "    train_fill_na[i] = train_fill_na[i].astype(int)\n",
    "    test_fill_na[i] = test_fill_na[i].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_fill_na['nerdiness']\n",
    "x_train = train_fill_na.drop('nerdiness',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_fill_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from string import ascii_lowercase\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_rfe_777(x_data, y_data, ratio=0.975, min_feats=30):\n",
    "    feats = x_data.columns.tolist()\n",
    "    archive = pd.DataFrame(columns=['model', 'n_feats', 'feats', 'score'])\n",
    "    while True:\n",
    "        # model = LGBMClassifier(objective = 'binary', num_iterations=10**3)\n",
    "        model = RandomForestClassifier(n_estimators=1000,n_jobs=32,random_state=777)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_data[feats], y_data, random_state=777)\n",
    "        model.fit(x_train, y_train)\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = val_pred[:,1]\n",
    "        score = roc_auc_score(y_val, val_pred)\n",
    "        n_feats = len(feats)\n",
    "        print(n_feats, score)\n",
    "        archive = archive.append({'model': model, 'n_feats': n_feats, 'feats': feats, 'score': score}, ignore_index=True)\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=feats).sort_values(ascending=False)        \n",
    "        next_n_feats = int(n_feats * ratio)\n",
    "        if next_n_feats < min_feats:\n",
    "            break\n",
    "        else:\n",
    "            feats = feat_imp.iloc[:next_n_feats].index.tolist()\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 0.8644707505645941\n",
      "76 0.8645658097893718\n",
      "74 0.8649417258146288\n",
      "72 0.8651966573719869\n",
      "70 0.8648923238235701\n",
      "68 0.8642606120661842\n",
      "66 0.8644999884776696\n",
      "64 0.8641605118219109\n",
      "62 0.8645796365857031\n",
      "60 0.8644622528460155\n",
      "58 0.8641812520164077\n",
      "56 0.8643114543485274\n",
      "54 0.8644093941558741\n",
      "52 0.8634052230723142\n",
      "50 0.8623576992210905\n",
      "48 0.8631138521454579\n",
      "46 0.8643370915333917\n",
      "44 0.8648796492602665\n",
      "42 0.8637647197769277\n",
      "40 0.8634772376365396\n",
      "39 0.8633317682168042\n",
      "38 0.8633500599161175\n",
      "37 0.8635882840945753\n",
      "36 0.8634704682675024\n",
      "35 0.8636297644835691\n",
      "34 0.8633182294787299\n",
      "33 0.8623919781536618\n",
      "32 0.8627915149559847\n",
      "31 0.8627726471401576\n",
      "30 0.863310307876665\n"
     ]
    }
   ],
   "source": [
    "lgbm_archive_4040 = lgbm_rfe_777(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, n_jobs=64, random_state=777)\n",
    "\n",
    "x_train_1 = x_train[lgbm_archive_4040.iloc[lgbm_archive_4040[lgbm_archive_4040['score']==lgbm_archive_4040['score'].max()].index[0],2]]\n",
    "\n",
    "model.fit(x_train_1, y_train)\n",
    "\n",
    "pred_y1 = model.predict_proba(test[lgbm_archive_4040.iloc[lgbm_archive_4040[lgbm_archive_4040['score']==lgbm_archive_4040['score'].max()].index[0],2]])\n",
    "pred_y1 = pred_y1[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_rfe_1234(x_data, y_data, ratio=0.975, min_feats=30):\n",
    "    feats = x_data.columns.tolist()\n",
    "    archive = pd.DataFrame(columns=['model', 'n_feats', 'feats', 'score'])\n",
    "    while True:\n",
    "        # model = LGBMClassifier(objective = 'binary', num_iterations=10**3)\n",
    "        model = RandomForestClassifier(n_estimators=1000, n_jobs=64, random_state=1234)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_data[feats], y_data, random_state=1234)\n",
    "        model.fit(x_train, y_train)\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = val_pred[:,1]\n",
    "        score = roc_auc_score(y_val, val_pred)\n",
    "        n_feats = len(feats)\n",
    "        print(n_feats, score)\n",
    "        archive = archive.append({'model': model, 'n_feats': n_feats, 'feats': feats, 'score': score}, ignore_index=True)\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=feats).sort_values(ascending=False)        \n",
    "        next_n_feats = int(n_feats * ratio)\n",
    "        if next_n_feats < min_feats:\n",
    "            break\n",
    "        else:\n",
    "            feats = feat_imp.iloc[:next_n_feats].index.tolist()\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 0.8755096719067063\n",
      "76 0.8758318196271769\n",
      "74 0.874746206246992\n",
      "72 0.8742775754711176\n",
      "70 0.8746363798933822\n",
      "68 0.8743368012010747\n",
      "66 0.8736207736260349\n",
      "64 0.8735299225062949\n",
      "62 0.873906695900027\n",
      "60 0.873875645517331\n",
      "58 0.8740655416078003\n",
      "56 0.8736571428242853\n",
      "54 0.8739525527152122\n",
      "52 0.8738217386029282\n",
      "50 0.8731587554316607\n",
      "48 0.8722657694256082\n",
      "46 0.8723554705311742\n",
      "44 0.872867658093886\n",
      "42 0.8727835633074177\n",
      "40 0.8721224489091828\n",
      "39 0.871635849161841\n",
      "38 0.871178574775934\n",
      "37 0.8713881648591317\n",
      "36 0.8709316092320838\n",
      "35 0.8708843148991812\n",
      "34 0.8708920774948551\n",
      "33 0.8701595184660651\n",
      "32 0.8697893576538331\n",
      "31 0.869975084942922\n",
      "30 0.87132937038449\n"
     ]
    }
   ],
   "source": [
    "lgbm_archive_1234 = lgbm_rfe_1234(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RandomForestClassifier(n_estimators=1000, n_jobs=64, random_state=1234)\n",
    "\n",
    "x_train_2 = x_train[lgbm_archive_1234.iloc[lgbm_archive_1234[lgbm_archive_1234['score']==lgbm_archive_1234['score'].max()].index[0],2]]\n",
    "\n",
    "model2.fit(x_train_2, y_train)\n",
    "\n",
    "pred_y2 = model2.predict_proba(test[lgbm_archive_1234.iloc[lgbm_archive_1234[lgbm_archive_1234['score']==lgbm_archive_1234['score'].max()].index[0],2]])\n",
    "pred_y2 = pred_y2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_rfe_99087(x_data, y_data, ratio=0.975, min_feats=30):\n",
    "    feats = x_data.columns.tolist()\n",
    "    archive = pd.DataFrame(columns=['model', 'n_feats', 'feats', 'score'])\n",
    "    while True:\n",
    "        # model = LGBMClassifier(objective = 'binary', num_iterations=10**3)\n",
    "        model = RandomForestClassifier(n_estimators=1000, n_jobs=64, random_state=99087)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_data[feats], y_data, random_state=99087)\n",
    "        model.fit(x_train, y_train)\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = val_pred[:,1]\n",
    "        score = roc_auc_score(y_val, val_pred)\n",
    "        n_feats = len(feats)\n",
    "        print(n_feats, score)\n",
    "        archive = archive.append({'model': model, 'n_feats': n_feats, 'feats': feats, 'score': score}, ignore_index=True)\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=feats).sort_values(ascending=False)        \n",
    "        next_n_feats = int(n_feats * ratio)\n",
    "        if next_n_feats < min_feats:\n",
    "            break\n",
    "        else:\n",
    "            feats = feat_imp.iloc[:next_n_feats].index.tolist()\n",
    "    return archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 0.8791360699741958\n",
      "76 0.8786869627370792\n",
      "74 0.8794423974538476\n",
      "72 0.8792378906901253\n",
      "70 0.8787941196661665\n",
      "68 0.8791636163718481\n",
      "66 0.878712922692982\n",
      "64 0.8786840782975345\n",
      "62 0.87874695907961\n",
      "60 0.8784573613493176\n",
      "58 0.8786800400821719\n",
      "56 0.8788034940946868\n",
      "54 0.8779670066267113\n",
      "52 0.8780737308898668\n",
      "50 0.8782557390251402\n",
      "48 0.878619899517664\n",
      "46 0.8780360889538079\n",
      "44 0.8776192874395926\n",
      "42 0.8782211257506033\n",
      "40 0.8777986995792757\n",
      "39 0.8767998181649312\n",
      "38 0.877167728428863\n",
      "37 0.8768393349866941\n",
      "36 0.8761451946102516\n",
      "35 0.8762713888403342\n",
      "34 0.8768303932241055\n",
      "33 0.8770961943281534\n",
      "32 0.8757491610607584\n",
      "31 0.8760924093665828\n",
      "30 0.8769472130256675\n"
     ]
    }
   ],
   "source": [
    "lgbm_archive_99087 = lgbm_rfe_99087(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = RandomForestClassifier(n_estimators=1000, n_jobs=64, random_state=99087)\n",
    "\n",
    "x_train_3 = x_train[lgbm_archive_99087.iloc[lgbm_archive_99087[lgbm_archive_99087['score']==lgbm_archive_99087['score'].max()].index[0],2]]\n",
    "\n",
    "model3.fit(x_train_3, y_train)\n",
    "\n",
    "pred_y3 = model3.predict_proba(test[lgbm_archive_99087.iloc[lgbm_archive_99087[lgbm_archive_99087['score']==lgbm_archive_99087['score'].max()].index[0],2]])\n",
    "pred_y3 = pred_y3[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_rfe_42(x_data, y_data, ratio=0.975, min_feats=30):\n",
    "    feats = x_data.columns.tolist()\n",
    "    archive = pd.DataFrame(columns=['model', 'n_feats', 'feats', 'score'])\n",
    "    while True:\n",
    "        # model = LGBMClassifier(objective = 'binary', num_iterations=10**3)\n",
    "        model = RandomForestClassifier(n_estimators=1000, n_jobs=64, random_state=5277)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_data[feats], y_data, random_state=5277)\n",
    "        model.fit(x_train, y_train)\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = val_pred[:,1]\n",
    "        score = roc_auc_score(y_val, val_pred)\n",
    "        n_feats = len(feats)\n",
    "        print(n_feats, score)\n",
    "        archive = archive.append({'model': model, 'n_feats': n_feats, 'feats': feats, 'score': score}, ignore_index=True)\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=feats).sort_values(ascending=False)        \n",
    "        next_n_feats = int(n_feats * ratio)\n",
    "        if next_n_feats < min_feats:\n",
    "            break\n",
    "        else:\n",
    "            feats = feat_imp.iloc[:next_n_feats].index.tolist()\n",
    "    return archive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 0.8816561288429459\n",
      "76 0.8811573487890648\n",
      "74 0.8811377095049514\n",
      "72 0.8816409661603583\n",
      "70 0.8804129332772651\n",
      "68 0.8817602459300473\n",
      "66 0.8817443612149554\n",
      "64 0.8809338075257737\n",
      "62 0.8818340376519733\n",
      "60 0.8816743240620508\n",
      "58 0.8811239908873721\n",
      "56 0.8811524389680365\n",
      "54 0.8813608175487402\n",
      "52 0.8825720992777364\n",
      "50 0.8805004436167705\n",
      "48 0.8805912753057952\n",
      "46 0.8815638530889128\n",
      "44 0.8808132280975771\n",
      "42 0.8809551796878972\n",
      "40 0.8805108408848306\n",
      "39 0.8800426750091265\n",
      "38 0.8792820859692333\n",
      "37 0.8792601361811065\n",
      "36 0.8790852599085963\n",
      "35 0.8790998449651807\n",
      "34 0.8791134191762591\n",
      "33 0.8791061988512174\n",
      "32 0.8789656913259057\n",
      "31 0.879255370766579\n",
      "30 0.8785435911239677\n"
     ]
    }
   ],
   "source": [
    "lgbm_archive_42 = lgbm_rfe_42(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, random_state=5277)\n",
    "\n",
    "x_train_4 = x_train[lgbm_archive_42.iloc[lgbm_archive_42[lgbm_archive_42['score']==lgbm_archive_42['score'].max()].index[0],2]]\n",
    "\n",
    "model4.fit(x_train_4, y_train)\n",
    "\n",
    "pred_y4 = model4.predict_proba(test[lgbm_archive_42.iloc[lgbm_archive_42[lgbm_archive_42['score']==lgbm_archive_42['score'].max()].index[0],2]])\n",
    "pred_y4 = pred_y4[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = (pred_y1 + pred_y2 + pred_y3 + pred_y4) * (1/4)\n",
    "# pred_all = pred_y4\n",
    "\n",
    "index = pd.read_csv('./data/test.csv').index.to_list()\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"index\" : index,\n",
    "    \"nerdiness\" : pred_all\n",
    "})\n",
    "submission.to_csv('./data/model2_random_forest_not_remove.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('./data/train.csv').drop('index',axis=1)\n",
    "# train.drop('introelapse',axis=1,inplace=True)\n",
    "# family size 이상치\n",
    "train = train.drop(1019)\n",
    "# age 이상치\n",
    "train = train.drop(train[train['age']>100].index.to_list())\n",
    "train = train.drop(train[train['introelapse']>3000].index.to_list())\n",
    "train = train.drop(train[train['testelapse']>10000].index.to_list())\n",
    "train = train.drop(train[train['surveyelapse']>10000].index.to_list()) # 나에 대한 추가 질문\n",
    "\n",
    "test = pd.read_csv('./data/test.csv').drop('index',axis=1)\n",
    "# test.drop('introelapse',axis=1,inplace=True)\n",
    "test.loc[test['familysize']>100,'familysize']= train['familysize'].mean()\n",
    "test.loc[test['age']>100,'age']= train['age'].mean()\n",
    "test.loc[test['introelapse']>3000,'introelapse']= train['introelapse'].mean()\n",
    "test.loc[test['testelapse']>10000,'testelapse']= train['testelapse'].mean()\n",
    "test.loc[test['surveyelapse']>10000,'surveyelapse']= train['surveyelapse'].mean()\n",
    "\n",
    "test_index = pd.read_csv('./data/test.csv')['index']\n",
    "\n",
    "pd.set_option('display.max_row', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "value = train['country'].value_counts().values\n",
    "rank = list(map(lambda x : 1 if x>1000 else (2 if x>100 else 3),value))\n",
    "# rank = list(map(lambda x : 1 if x>2000 else (2 if x>1000 else (3 if x>500 else (4 if x>200 else (5 if x>100 else 6)))),value))\n",
    "\n",
    "temp_dict = {i : 0 for i in train['country'].value_counts().index.to_list()}\n",
    "\n",
    "rank_dict = dict(zip(train['country'].value_counts().index.to_list(), rank))\n",
    "rank_dict['nan'] = 0\n",
    "train['country'] = train['country'].fillna('nan')\n",
    "train['country'] = train['country'].apply(lambda x : rank_dict[x])\n",
    "train['Ex'] = (train['TIPI1']+train['TIPI6'])/2\n",
    "train['Ag'] = (train['TIPI7']+train['TIPI2'])/2\n",
    "train['Con'] = (train['TIPI3']+train['TIPI8'])/2\n",
    "train['Es'] =(train['TIPI9']+train['TIPI4'])/2\n",
    "train['Op'] =(train['TIPI5']+train['TIPI10'])/2\n",
    "\n",
    "train['mach_score'] = train[train.columns[:20]].apply(lambda x : x.mean(),axis=1)\n",
    "train['T'] = train['Q1'] + train['Q2'] - train['Q3'] - train['Q6'] - train['Q7'] - train['Q10'] + train['Q12'] + train['Q15'] - train['Q16']\n",
    "train['V'] = -train['Q4'] + train['Q5'] + train['Q8'] - train['Q11'] + train['Q13'] - train['Q14'] - train['Q17'] + train['Q18'] + train['Q20']\n",
    "train['M'] = -train['Q9'] + train['Q19']\n",
    "train['introelapse'] = np.log1p(train['introelapse'])\n",
    "train['testelapse'] = np.log1p(train['testelapse'])\n",
    "train['surveyelapse'] = np.log1p(train['surveyelapse'])\n",
    "train.drop('hand',axis=1,inplace=True)\n",
    "# train.drop(['VCL7','VCL8','VCL11'],axis=1,inplace=True)\n",
    "# train.drop([('TIPI'+str(i)) for i in range(1,11)],axis=1,inplace=True)\n",
    "# train.drop([('Q'+str(i)) for i in range(1,20)],axis=1,inplace=True)\n",
    "\n",
    "train['nature_score'] = train[[('Q'+str(i)) for i in range(20,27)]].apply(lambda x : x.mean(),axis=1)\n",
    "# train.drop([('Q'+str(i)) for i in range(20,27)],axis=1,inplace=True)\n",
    "train_fill_na = train.fillna(train.mean())\n",
    "\n",
    "\n",
    "value = test['country'].value_counts().values\n",
    "rank = list(map(lambda x : 1 if x>1000 else (2 if x>100 else 3),value))\n",
    "# rank = list(map(lambda x : 1 if x>2000 else (2 if x>1000 else (3 if x>500 else (4 if x>200 else (5 if x>100 else 6)))),value))\n",
    "\n",
    "temp_dict = {i : 0 for i in test['country'].value_counts().index.to_list()}\n",
    "\n",
    "rank_dict = dict(zip(test['country'].value_counts().index.to_list(), rank))\n",
    "rank_dict['nan'] = 0\n",
    "test['country'] = test['country'].fillna('nan')\n",
    "test['country'] = test['country'].apply(lambda x : rank_dict[x])\n",
    "\n",
    "test['Ex'] = (test['TIPI1']+test['TIPI6'])/2\n",
    "test['Ag'] = (test['TIPI7']+test['TIPI2'])/2\n",
    "test['Con'] = (test['TIPI3']+test['TIPI8'])/2\n",
    "test['Es'] =(test['TIPI9']+test['TIPI4'])/2\n",
    "test['Op'] =(test['TIPI5']+test['TIPI10'])/2\n",
    "\n",
    "test['mach_score'] = test[test.columns[:20]].apply(lambda x : x.mean(),axis=1)\n",
    "test['T'] = test['Q1'] + test['Q2'] - test['Q3'] - test['Q6'] - test['Q7'] - test['Q10'] + test['Q12'] + test['Q15'] - test['Q16']\n",
    "test['V'] = -test['Q4'] + test['Q5'] + test['Q8'] - test['Q11'] + test['Q13'] - test['Q14'] - test['Q17'] + test['Q18'] + test['Q20']\n",
    "test['M'] = -test['Q9'] + test['Q19']\n",
    "\n",
    "test['introelapse'] = np.log1p(test['introelapse'])\n",
    "test['testelapse'] = np.log1p(test['testelapse'])\n",
    "test['surveyelapse'] = np.log1p(test['surveyelapse'])\n",
    "test.drop('hand',axis=1,inplace=True)\n",
    "# test.drop(['VCL7','VCL8','VCL11'],axis=1,inplace=True)\n",
    "# test.drop([('TIPI'+str(i)) for i in range(1,11)],axis=1,inplace=True)\n",
    "# test.drop([('Q'+str(i)) for i in range(1,20)],axis=1,inplace=True)\n",
    "\n",
    "test['nature_score'] = test[[('Q'+str(i)) for i in range(20,27)]].apply(lambda x : x.mean(),axis=1)\n",
    "# test.drop([('Q'+str(i)) for i in range(20,27)],axis=1,inplace=True)\n",
    "test_fill_na = test.fillna(test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "y_train = train_fill_na['nerdiness']\n",
    "train_x = train_fill_na.drop('nerdiness',axis=1)\n",
    "test_x = test_fill_na.copy()\n",
    "\n",
    "ss.fit(train_x)\n",
    "train_x = ss.transform(train_x)\n",
    "test_x = ss.transform(test_x)\n",
    "# train_fill_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('Used',DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "train_y = y_train.copy()\n",
    "\n",
    "# train_y = 2 - train_y.to_numpy()\n",
    "# train_x = train_x.to_numpy()\n",
    "# test_x = test_x.to_numpy()\n",
    "\n",
    "train_y_t = torch.tensor(train_y, dtype=torch.float32)\n",
    "train_x_t = torch.tensor(train_x, dtype=torch.float32)\n",
    "test_x_t = torch.tensor(test_x, dtype=torch.float32)\n",
    "\n",
    "train_x_t[:, :26] = (train_x_t[:, :26] - 3.) / 2.\n",
    "test_x_t[:, :26] = (test_x_t[:, :26] - 3.) / 2\n",
    "\n",
    "train_x_t[:, 30:40] = (train_x_t[:, 30:40] - 3.) / 2.\n",
    "test_x_t[:, 30:40] = (test_x_t[:, 30:40] - 3.) / 2\n",
    "\n",
    "test_len = len(test_x_t)\n",
    "\n",
    "N_REPEAT = 5\n",
    "N_SKFOLD = 7\n",
    "N_EPOCH = 48\n",
    "BATCH_SIZE = 1024\n",
    "LOADER_PARAM = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': 4, # in colab use 2\n",
    "    'pin_memory': True\n",
    "}\n",
    "prediction = np.zeros((test_len, 1), dtype=np.float32)\n",
    "\n",
    "for repeat in range(N_REPEAT):\n",
    "\n",
    "    skf, tot = StratifiedKFold(n_splits=N_SKFOLD, random_state=repeat, shuffle=True), 0.\n",
    "    for skfold, (train_idx, valid_idx) in enumerate(skf.split(train_x, train_y)):\n",
    "        train_idx, valid_idx = list(train_idx), list(valid_idx)\n",
    "        train_loader = DataLoader(TensorDataset(train_x_t[train_idx, :], train_y_t[train_idx]),\n",
    "                                  shuffle=True, drop_last=True, **LOADER_PARAM)\n",
    "        valid_loader = DataLoader(TensorDataset(train_x_t[valid_idx, :], train_y_t[valid_idx]),\n",
    "                                  shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "        test_loader = DataLoader(TensorDataset(test_x_t, torch.zeros((test_len,), dtype=torch.float32)),\n",
    "                                 shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "        model = nn.Sequential(\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(77, 180, bias=False),\n",
    "            nn.LeakyReLU(0.5, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(180, 32, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Linear(128, 32, bias=False),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        ).to(DEVICE)\n",
    "        # criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.20665], device=DEVICE))\n",
    "        criterion = torch.nn.BCELoss()\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=4e-2)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=N_EPOCH // 4, eta_min=1.2e-5)\n",
    "        prediction_t, loss_t = np.zeros((test_len, 1), dtype=np.float32), 1.\n",
    "\n",
    "        # for epoch in range(N_EPOCH):\n",
    "        for epoch in tqdm(range(N_EPOCH), desc='{:02d}/{:02d}'.format(skfold + 1, N_SKFOLD)):\n",
    "            model.train()\n",
    "            for idx, (xx, yy) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "                pred = model(xx).squeeze()\n",
    "                loss = criterion(pred, yy)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step(epoch + idx / len(train_loader))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                running_acc, running_loss, running_count = 0, 0., 0\n",
    "                for xx, yy in valid_loader:\n",
    "                    xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "                    pred = model(xx).squeeze()\n",
    "                    loss = criterion(pred, yy)\n",
    "                    running_loss += loss.item() * len(yy)\n",
    "                    running_count += len(yy)\n",
    "                    # running_acc += ((torch.sigmoid(pred) > 0.5).float() == yy).sum().item()\n",
    "                    running_acc += (((pred) >\n",
    "                                    0.5).float() == yy).sum().item()\n",
    "                # print('R{:02d} S{:02d} E{:02d} | {:6.4f}, {:5.2f}%'.format(repeat + 1, skfold + 1, epoch + 1, running_loss / running_count,running_acc / running_count * 100))\n",
    "\n",
    "                if running_loss / running_count < loss_t:\n",
    "                    loss_t = running_loss / running_count\n",
    "                    for idx, (xx, _) in enumerate(test_loader):\n",
    "                        xx = xx.to(DEVICE)\n",
    "                        pred = ((model(xx).detach().to('cpu'))).numpy()\n",
    "                        prediction_t[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction)), :] \\\n",
    "                            = pred[:, :].copy()\n",
    "        prediction[:, :] += prediction_t[:, :].copy() / (N_REPEAT * N_SKFOLD)\n",
    "        tot += loss_t\n",
    "    print('R{} -> {:6.4f}'.format(repeat + 1, tot / N_SKFOLD))\n",
    "\n",
    "df = pd.read_csv('./data/sample_submission.csv')\n",
    "df.iloc[:, 1:] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df['nerdiness']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/model3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = pd.read_csv('./data/model1.csv', index_col = 'index')\n",
    "model2 = pd.read_csv('./data/model2.csv', index_col='index')\n",
    "\n",
    "pred_y = (model1)*(0.7) + (model2)*(0.3)\n",
    "\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "index = test['index']\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'index': index,\n",
    "    'voted': pred_y['voted']\n",
    "    })\n",
    "\n",
    "submission.to_csv('./data/combined_model1_model2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_12 = pd.read_csv('./data/combined_model1_model2.csv', index_col = 'index')\n",
    "model3 = pd.read_csv('./data/model3.csv', index_col='index')\n",
    "model3['voted'] = model3['voted']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = (model3)*(0.8) + (combined_12)*(0.2)\n",
    "\n",
    "test = pd.read_csv('./data/test_x.csv')\n",
    "index = test['index']\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'index': index,\n",
    "    'voted': pred_y['voted']\n",
    "    })\n",
    "\n",
    "submission.to_csv('./data/submission_final_fix_lgbm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('for_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d5361de2d3a86ff8022af11ead2fa25aee948dfb14ed55cb3d2da795443f4cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
